#!/usr/bin/env Rscript

## (c) Martin Renner
## licence: GPL-3
## NOAA/KBRR LCI study



## ------------------------------------------------------------------
## new workflow, 2023-08-10

## import CNV files generated by CTD_hexprocessing.R
## extract date, transect, station, and cast information from filenames
## match those to MasterStationList

## Next step: QAQC. Check against notes. Check metadata time and date
## against filename, and internal date. Check note-positions against
## master-list (do that in filemaker??).
## All these new steps in next script, CTD_cleanup.R
## ------------------------------------------------------------------





## ------------------------------------------------------------------
### old notes ###

## import CNV files, generated from CTD by CTD_hexprocessing.R
## import notebook database tables
## QAQC on notebook tables: match with master list

## based on early dataSetup.R version -- pulled-out CTD import section.
## new dataSetup.R to read-in output file produced here instead of doing the
## heavy lifting of CTD import and plotting itself.
##
## abandoned earlier attempts reading in various .CNV files
## new read .CNV files freshly reprocessed by ctd_workflow.R -> CTD_hexprocessing.R
## this guarantees that there's a 1:1 match between HEX and CNV files
## Outsource as much of the post-merge QAQC to CTD_cleanup.R, as possible.


## Alternative sources of location, date, and time information
## location and date:
##  - file name
##  - metadata
## => designate filename as gold standard
##    trust filename over metadata, because it's more visible
## => check against metadata!
##    => fix metadata in file, as appropriate! -- carefully!
## => check against notebook entries (low priority)






## missing issues:
# metadata dates and times
# duplicate station names (need sym-links, something like that)
#    - need algorithm on how to find station in Q for either transect
#      on any date X
#    - delete duplicate file (only one)
# fix meta-data dates? -- in script
# fix medata-data? times 2012-04-26_T9  (notes are good)
# x done x  fix file-names: 2019-15-14 to 2019-05-14  -- redo in code?
# anything that can/should be done about missing notes or missing files?
# check that station numbers within transects are in chronological order
# x negative pressures: delete. Aircasts?  Calibration file is correct!

## 2020-10-13: resolve metadata-filename date mismatches!

## make SURE, fileDB alsoways has station, transect, lat, lon
##            lat lon can be from notebook or master list -- cannot be NA




# rm (list = ls())

## CAREFUL with this!!
# system ("rm -r ~/tmp/LCI_noaa/")
# ## don't  ##  unlink ("~/tmp/LCI_noaa/", recursive = TRUE)

sink ("CTD_cnv-import.log.txt")

print (sTime <- Sys.time())
runParallel <- FALSE  ## 21 minutes on Dell Latitude 5420
runParallel <- TRUE   ##  7 minutes on same Dell (4 cores, 8 threads)

## file structure:
## source files in ~/GISdata/LCI/
GISF <- "~/GISdata/LCI/"
tmpF <- "~/tmp/LCI_noaa/"
mediaF <- paste0 (tmpF, "media/")
cacheF <- paste0 (tmpF, "cache/")
dirL <- c (GISF=GISF, tmpF=tmpF, mediaF=mediaF, cacheF=cacheF)
rm (GISF, tmpF, mediaF, cacheF)
x <- lapply (dirL, dir.create, showWarnings = FALSE, recursive = TRUE); rm (x)

set.seed(7)

## better solution:
## put all this code into a package
## make required packages a dependency -> they will install automatically, if missing, during package install


## hard-code location to AK -- how?
# system ("mkdir -p ~/tmp/LCI_noaa/cache")
# dir.create("~/tmp/LCI_noaa/cache/", showWarnings = FALSE, recursive = TRUE)
# dir.create("~/tmp/LCI_noaa/media/2019/", showWarnings = FALSE, recursive = TRUE)


############################
## define basic functions ##
############################






##############
## CTD data ##
##############

require (oce)
## read in processed files of individual CTD casts
fNf <- list.files ("~/tmp/LCI_noaa/CTD-cache/CNV", full.names=TRUE, ignore.case=TRUE)  # break tmp-file reliance?
# fNf <- list.files ("~/GISdata/LCI/CTD-processing/", ".hex", full.names=TRUE, ignore.case=TRUE, recursive=TRUE)


## cut-out bad files for now -- fix this later -- why bad?
badF <- c ("2012_10-28_t6_s22_cast007_4141"  ## casts that are empty/but don't cause major trouble
           , "2012_10-29_t4_s07b_cast065_4141"
           , "2013-04-19-cookinlet-tran6-cast059-s27_5028"
           , "2013-04-19-cookinlet-tran6-cast076-s05b_5028"
           , "2013_04-19_t6_s05b_cast076_5028"  ## same as above?!
           , "2013_04-20_t3_s05_cast117_5028"
           , "2015_06-26_t9_s01b_cast117_5028"
           , "2015_06-26_t9_s06b_cast111_5028"
           , "2021_05-01_ab_s06_surface-duplicate_cast036_5028"
           )
## casts that crash readCNV()
badF <- c ("2012_10-28_t6_s23_cast006_4141"  ## error in "upoly" %in% names (ctdF@data)
           , "2012_10-28_t6_s23_cast006_4141", badF)

for (i in 1:length (badF)){
  if (length (grep (badF [i], fNf)) > 0){
    fNf <- fNf [-grep (badF [i], fNf)]
  }
}
rm (badF)
fN <- gsub ("^.*/", "", fNf)




## find dates to link to notebook DB
## deem file-names inherently unreliable and go with CTD metadata-dates instead
## match time-stamps to closest timestamps in notebooks and hope for the best
getMeta <- function (i){  # slow and inefficient to read files twice, once just for metadata -- still cleaner?
  require ("oce")
  ctdF <- suppressWarnings (try (read.ctd (fNf[i]))) ## still warning for missing values and NAs introduced by coercion
  if (class (ctdF) == "try-error"){
    print (i)
    print (fNf[i])
    ## as of 2021-02-02, this affects 7 casts could address this in hex-conversion or drop them
    # fNf [c (195, 720, 762, 900, 1858, 1864, 3527)]
    ## return empty DF
    cT <- NA
    instSerNo <- NA
    depth_bottom <- NA
  }else{
    cT <- ctdF@metadata$startTime   # fix time zone later, because import is slow
    instSerNo <- trimws (ctdF@metadata$serialNumberTemperature) # serial number of CTD instrument
    depth_bottom <- ctdF@metadata$waterDepth
  }
  outDF <- data.frame (time = cT
                       , file = fN [i], path = fNf [i]
                       , instSerNo, depth_bottom
  )
  return (outDF)
}



if (runParallel){
  require ("parallel") ## revert to require ("parallel")
  cl <- makeCluster (detectCores()-1, type="PSOCK")
  # registerDoParallel (cl)
  clusterExport (cl=cl, list ("getMeta", "fNf", "read.ctd", "fN"))
  fileDB <- parLapply (cl=cl, seq_along (fNf), fun=getMeta)
  ## shut down cluster farther down
}else{
  fileDB <- lapply (1:length (fNf), FUN = getMeta)
}

rm (getMeta)
fileDB <- as.data.frame (do.call (rbind, fileDB)) # CTD metadata database
fileDB <- subset (fileDB, !is.na (time))
## ok to ignore warnings regarding NAs introduced by coersion


save.image ("~/tmp/LCI_noaa/cache/CNVx0.RData")
# rm (list = ls()); base::load ("~/tmp/LCI_noaa/cache/CNVx0.RData")



## read CTD data from CNV file and apply basic processing:
## trim (keep only down-cast)
## apply basic QAQC: skip files with negative pressure (air-casts?)
## build flat table combining data and some metadata

unlink ("~/tmp/LCI_noaa/cache/badCTDfile.txt")
readCNV <- function (i){
  require (oce)
  ctdF <- try (read.ctd (fNf [i]
                         # , columns = "define name of dV/dT"
                         , deploymentType = "profile"
                         ))
  if (class (ctdF) == "try-error"){
  } #else{
  ## more CTD import processing steps
  ## zero-depth
  ## cut-out surface, up-cast?
  # cut bad flags!
  ## aggregate depth bins
  ## add derived variables ??

  ## best: manually inspect and read-in from separate table
  # ?plotScan

  ## fix-up missing fields
  meta <- function (x){rep (x, length (ctdF@data$temperature))}
  if ("upoly" %in% names (ctdF@data)){
    names (ctdF@data)[which (names (ctdF@data) == "upoly")] <- "turbidity"
  }
    if (!"beamAttenuation" %in% names (ctdF@data)){
      ctdF@data$beamAttenuation <- meta (NA)
      ctdF@data$beamTransmission <- meta (NA)
    }
  if (!"turbidity" %in% names (ctdF@data)){
    ctdF@data$turbidity <- meta (NA)
  }

  # print (ctdF@metadata$units)
  cDFo <- data.frame (File.Name = meta (gsub (".cnv$", "", fN [i]))
                      , path = meta (fNf [i])
                      #, timestamp = meta (ctdF@metadata$startTime)  ## NOT needed here -- cut!
                      , depth_bottom = meta (ctdF@metadata$waterDepth)
                      #, CTDserial = trimws (meta (ctdF@metadata$serialNumberTemperature))
                      , density = ctdF@data$sigmaTheta # use sigmaTheta preferable when comparing samples from different depth
                      , depth = ctdF@data$depth
                      , oxygen_umol_kg = ctdF@data$oxygen4 # umol/kg
                      , Oxygen_SBE.43..mg.l. = ctdF@data$oxygen
                      , O2percsat = ctdF@data$oxygen3 # SBE43 %
                      , O2GGsat_umol_kg = ctdF@data$oxygen8
                      , par = ctdF@data$par
                      , salinity = ctdF@data$salinity
                      , temperature = ctdF@data$temperature
                      , pressure = ctdF@data$pressure
                      , nitrogen = ctdF@data$nitrogenSaturation  # mg/l
                      , fluorescence = ctdF@data$fluorescence
                      , turbidity = ctdF@data$turbidity
                      , beamAttenuation = ctdF@data$beamAttenuation
                      , beamTransmission = ctdF@data$beamTransmission
  )
  cDF <- subset (cDFo, density > 0) ## still necessary?
  if (0){
    ## depth bins
    cDo <- subset (cDF, density >0)
    depthBin <- factor (floor (cDFo$depth))
    cDF <- aggregate (.~File.Name+depthBin, cDFo, fun=mean, na.rm=TRUE)
  }
  return (cDF)
}


rCNV <- function (i){
  x <- try (readCNV (i))
  if (class (x) == "try-error"){
    cat (i, fNf [i], "\n\n")
  }else{return (x)}
}

if (runParallel){
  clusterExport(cl=cl, list ("rCNV", "fNf", "readCNV"))
  CTDx <- parLapply (cl=cl, seq_along (fNf), rCNV)
  stopCluster (cl)
  rm (cl)
}else{
  CTDx <- lapply (seq_along (fNf), rCNV)
}
CTD1 <- as.data.frame (do.call (rbind, CTDx))
rm (rCNV, readCNV, CTDx)
rm (fN, fNf)
save.image ("~/tmp/LCI_noaa/cache/CNVx.RData")  ## this to be read by dataSetup.R -- not yet!
# rm (list = ls()); base::load ("~/tmp/LCI_noaa/cache/CNVx.RData")





# ---------- extract date, transect, station, cast-# from file names --------- #
## goal: simplify R code
require ("stringr")
## date
fileDB$FN_date <- substring(fileDB$file, 1, 10) %>%
  str_replace_all ("_", "-") %>%
  as.Date
## transect
fileDB$FN_transect <- substring (fileDB$file, 12, 15) %>%
  str_replace_all ("-", "_") %>%
  str_replace ("_$", "") %>%
  str_replace ("^_", "") %>%
  str_replace ("(^t)([0-9])", "\\2") %>%   # leading t
  str_replace ("^0", "") %>%              # leading 0
  str_replace ("_[0-9,n,p,s,t]$", "") %>%  # trailing tail
  str_replace ("^(sadi|stev|subb|tutk)", "Subbay") %>%
  str_replace ("(alon|ab)", "AlongBay")
# summary (factor (fileDB$FN_transect))
# fileDB$file [fileDB$FN_transect == "3_t"] # "2018_09-13_t3_testbluff_cast005_5028.cnv"
# fileDB$file [fileDB$FN_transect == "9_n"]   # 2015_07-29_t9_north_cast149_5028.cnv

## station number
fileDB$FN_station <- fileDB$file %>%
  str_replace_all("[-,_]", " ") %>%
  word (start=5L) %>%
  str_replace_all ("^(spgrm|sptgm|sptgr|ptgm|ptgr|pgrm)", "PGRM")%>%
  str_replace ("spogi|pogibshi|pogipoint|pt.pogi|pogi", "POGI") %>%
  str_replace ("^(skb|kb|s)([0-9])", "\\2") %>%  # AlongBay variations
  str_replace ("^jbay", "jakolof") %>%
  str_replace ("^(kbay)", "kasitsna") %>%
  str_replace ("^0", "") %>%                         # no leading zero
  str_replace_all ("([0-9])([a-z]+)", "\\1")         # strip-out all duplicates; match by cast#. Clean.
# levels (factor (fileDB$FN_station))
# fileDB$file [fileDB$FN_station == "seldovia"]         # 2015_07-29_t9_north_cast149_5028.cnv

## fixing lots of small one-off casts
sbbStns <- c ("bear", "chinapoot", "halibut", "jakolof", "kasitsna", "peterson"
              , "sadie", "seldovia", "tutka")
for (i in seq_along(sbbStns)){
  fileDB$FN_transect [grep (toupper(sbbStns [i])
                            , toupper (fileDB$FN_station))] <- "Subbay" # some are "AlongBay"
  fileDB$FN_station <- str_replace_all (toupper (fileDB$FN_station)
                                        , paste0 ("(", toupper (sbbStns [i]), ")([A-D])")
                                        , paste0 (tools::toTitleCase (sbbStns [i]), "_\\2"))
}
rm (sbbStns, i)
# summary (factor (fileDB$FN_transect))
# summary (factor (fileDB$FN_station))



## cast number
fileDB$FN_cast <- fileDB$file %>%
  str_replace_all ("[-,_]", " ") %>%
  str_extract ("cast[0-9]+") %>%
  str_replace ("cast", "")
# head (fileDB$FN_cast)
# summary (factor (fileDB$FN_cast))
# levels (factor (fileDB$FN_cast))


## main station list
stnMaster <- read.csv ("~/GISdata/LCI/MasterStationLocations.csv")
fileDB$FN_matchname <- with (fileDB, paste (FN_transect, FN_station, sep="_")) %>%
  str_replace_all("Subbay_", "")
fileDB$match <- match (toupper (fileDB$FN_matchname), toupper (stnMaster$Match_Name))
## alert if there are any new mismatches
badM <- which (is.na (fileDB$match))
if (length (badM) != 59){
  cat ("\n\n##\n## The following casts don't have a match in main station table:\n")
  print (fileDB [badM, which (names (fileDB)%in% c("file", "FN_matchname"))])
  stop ("The number of non-matched CTD casts has changed from 59\n\n")
}
rm (badM)
## as of 2022-08-11, these are 59 files (1.3%)
## -> match with notes by date and cast-number; check against time
## -> fix filenames accordingly


# save.image ("~/tmp/LCI_noaa/cache/CNVx2.RData")




# mdata <- .....    # cook-up from notebooks
mdata <- with (fileDB, data.frame (isoTime = localTime
                                   , File.Name = gsub (".cnv", "", file, fixed = TRUE)
                                   , Date = format (FN_date,  "%Y-%m-%d") # format (localTime, "%Y-%m-%d") #??
                                   , Transect = FN_transect               # stationEv$Transect [consensNo]
                                   , Station = FN_station                 # stationEv$Station [consensNo]
                                   , Time = format (localTime, "%H:%M")
                                   , CTD.serial = instSerNo
                                   , latitude_DD =  stnMaster$Lat_decDegree [match (FN_matchname, stnMaster$Match_Name)] # stationEv$LatNotes [consensNo]
                                   , longitude_DD = stnMaster$Lat_decDegree [match (FN_matchname, stnMaster$Match_Name)] # stationEv$LonNotes [consensNo]
                                   , Bottom.Depth = depth_bottom # rep (NA, length (consensNo))## put into FileDB from metatdata/masterstation -- should also be in stationEv, but isn't
                                   , comment="" # , comments = stationEv$Comments [consensNo]
))
summary (mdata)
# summary (fileDB$consensNo)
# rm (stationEv)  ## use in troubleshooting

## FIX here: lat-long: all NA!


  ## glue it all together: add transect, station, lat, lon to CTD1
  # stationMatch <- stationEv [match (),]
  # fileDB <- cbind (fileDB, )
  #
  #
  # physOc <- with (CTD1, data.frame (timestamp, File.Name,
  #                                   stationEv$Station
  #                                   )

if (0){
  ## read in metadata and match based on File.Name
  ## metadata currently harvested from aggregated files.
  ## In future, should be kept from field-notes DB
  mdata <- read.csv ("~/GISdata/LCI/CTD/ctd_metadata_m.csv")  # currently 2012-02-04 to 2016-12-13 (as of 2020-07-02)
}

xmatch <- match (as.character (CTD1$File.Name), as.character (mdata$File.Name))
## finding bad matches
summary (xmatch)
badFileNames <- as.character (unique (CTD1$File.Name [which (is.na (xmatch))]))
length (badFileNames)                   # < 26 -- not too bad
print (badFileNames)
rm (badFileNames)

physOc <- data.frame (mdata [xmatch,]
                      , CTD1 [,which (names (CTD1) == "density"):ncol (CTD1)]) # watch out for isoTime
# physOc <- data.frame (mdata [xmatch,2:ncol (mdata)], CTD1)
rm (xmatch, CTD1, mdata)



## DANGEROUS -- REVERSE?!?
print (names (physOc))
nNames <- c ("isoTime"
                     , "File.Name", "Date", "Transect", "Station"
                     , "Time", "CTD.serial", "latitude_DD", "longitude_DD"
                     , "Bottom.Depth", "comments"
                     # , "timestamp"
                     # , "depth_bottom" # , "CTDserial"
                     , "Density_sigma.theta.kg.m.3"
                     , "Depth.saltwater..m."
                     , "Oxygen_umol_kg"  # verify which is exported!!
                     , "Oxygen_SBE.43..mg.l."
                     , "Oxygen_sat.perc."
                     , "Oxygen.Saturation.Garcia.Gordon.umol_kg"
                     , "PAR.Irradiance"
                     , "Salinity_PSU"
                     , "Temperature_ITS90_DegC"
                     , "Pressure..Strain.Gauge..db."
                     , "Nitrogen.saturation..mg.l."
                     , "Fluorescence_mg_m3"
                     , "turbidity"
                     , "beamAttenuation"
                     , "beamTransmission"
)
if (length (nNames) == ncol (physOc)){
  names (physOc) <- nNames
}else{stop ("Lenght of new names does not match number of columns in physOc\n")}
# print (summary (physOc))
rm (i, nNames)



cat ("\n\n#\n#\n#\n# ")
print (round (difftime(Sys.time(), sTime)))
cat ("\n# ", format (Sys.time(), format = "%Y-%m-%d %H:%M"
                            , usetz = FALSE)
     , " \n# \n# End of CTD_cnv-Import.R\n#\n#\n")
rm (sTime)

save.image ("~/tmp/LCI_noaa/cache/CNV2.RData")   ## to be used by CTD_cleanup.R
# rm (list = ls()); load ("~/tmp/LCI_noaa/cache/CNV2.RData")



# ## troubleshooting -- see Mark Dickson's email
# dick <- subset (physOc, format (isoTime, "%Y")=="2019")
# levels (factor (with (dick, paste (Date, Transect, Station))))
# levels (factor (dick$File.Name))
# levels (factor (dick$File.Name [grep ("2019_05-14", dick$File.Name)]))
# x <- subset (dick, File.Name == "2019_05-14_alongbay_skb12_cast203_4141")
# x$Transect
# x$Station
#
# dickFdb <- subset (fileDB, file=="2019_05-14_alongbay_skb12_cast203_4141.cnv")

sink()

## EOF
